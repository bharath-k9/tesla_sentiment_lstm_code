{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bec184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching news: 426\n",
      "Average Sentiment Score (Dec 2020): 0.0\n",
      "X_train shape: (1148, 60, 2)\n",
      "y_train shape: (1148,)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\lstm_sentiment_analysis\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.1095e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.3579e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.6587e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.3033e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.2784e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.1003e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.2090e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0924e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.8370e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.7272e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5941e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5799e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.5923e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.6455e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.3315e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5280e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.2900e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.4118e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.4745e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.2135e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.2301e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.2305e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.2202e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.1664e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.2275e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.4445e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.1116e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.0601e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.1447e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.0808e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.0161e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8263e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.6816e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.7120e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.1726e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.4863e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.0022e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.4482e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.4200e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.7934e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.3277e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.8351e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.9690e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.9039e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.8175e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1517e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.0992e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.5721e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.1608e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.3179e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Actual Price  Predicted Price\n",
      "0  2021-01-04        243.26       238.309998\n",
      "1  2021-01-05        245.04       245.710007\n",
      "2  2021-01-06        251.99       253.960007\n",
      "3  2021-01-07        272.01       262.779999\n",
      "4  2021-01-08        293.34       272.000000\n",
      "5  2021-01-11        270.40       281.510010\n",
      "6  2021-01-12        283.15       291.260010\n",
      "7  2021-01-13        284.80       301.220001\n",
      "8  2021-01-14        281.67       311.369995\n",
      "9  2021-01-15        275.39       321.739990\n",
      "10 2021-01-19        281.52       332.329987\n",
      "11 2021-01-20        283.48       343.160004\n",
      "12 2021-01-21        281.66       354.230011\n",
      "13 2021-01-22        282.21       365.559998\n",
      "14 2021-01-25        293.60       377.130005\n",
      "15 2021-01-26        294.36       388.959991\n",
      "16 2021-01-27        288.05       401.010010\n",
      "17 2021-01-28        278.48       413.269989\n",
      "18 2021-01-29        264.51       425.709991\n",
      "Saved to 'tesla_2021_january_comparison.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# --- Fetch News Articles ---\n",
    "def fetch_tesla_news(api_key, start_date, end_date):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        'q': 'Tesla',\n",
    "        'from': start_date.strftime('%Y-%m-%d'),\n",
    "        'to': end_date.strftime('%Y-%m-%d'),\n",
    "        'sortBy': 'publishedAt',\n",
    "        'apiKey': api_key,\n",
    "        'language': 'en'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get('articles', [])\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# --- Sentiment Analysis ---\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    score = blob.sentiment.polarity\n",
    "    return ('Positive' if score > 0 else 'Negative' if score < 0 else 'Neutral'), score\n",
    "\n",
    "# --- News Sentiment for Dec 2020 ---\n",
    "api_key = '8fa805af31b54a0ab98c3d5e804f49df'\n",
    "start_date = datetime(2020, 12, 1)\n",
    "end_date = datetime(2020, 12, 31)\n",
    "articles = fetch_tesla_news(api_key, start_date, end_date)\n",
    "\n",
    "scores = []\n",
    "for article in articles:\n",
    "    title = article.get('title', '')\n",
    "    desc = article.get('description', '') or ''\n",
    "    combined = title + \" \" + desc\n",
    "    _, score = analyze_sentiment(combined)\n",
    "    scores.append(score)\n",
    "\n",
    "average_sentiment = np.mean(scores) if scores else 0.0\n",
    "print(\"Average Sentiment Score (Dec 2020):\", average_sentiment)\n",
    "\n",
    "# --- Download Tesla Data ---\n",
    "df = yf.download('TSLA', start='2015-01-01', end='2020-12-31')\n",
    "\n",
    "# --- Handle MultiIndex Columns ---\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = ['_'.join(col).strip().lower() for col in df.columns.values]\n",
    "else:\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# --- Get Close Column ---\n",
    "close_col = next((col for col in df.columns if 'close' in col), None)\n",
    "if close_col is None:\n",
    "    raise ValueError(\"No 'close' column found.\")\n",
    "\n",
    "# --- Scale and Prepare Data ---\n",
    "df = df.dropna(subset=[close_col])\n",
    "data = df[[close_col]].values\n",
    "\n",
    "scaler_close = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_close = scaler_close.fit_transform(data)\n",
    "\n",
    "sentiment_feature = np.full((len(scaled_close), 1), average_sentiment)\n",
    "combined_data = np.hstack((scaled_close, sentiment_feature))\n",
    "\n",
    "train_len = int(np.ceil(len(combined_data) * 0.8))\n",
    "train_data = combined_data[:train_len]\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for i in range(60, len(train_data)):\n",
    "    X_train.append(train_data[i-60:i])\n",
    "    y_train.append(train_data[i, 0])  # Predict close price only\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# --- Build and Train LSTM ---\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=False, input_shape=(60, 2)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# --- Prediction for Jan 2021 ---\n",
    "df_2021 = yf.download('TSLA', start='2021-01-01', end='2021-01-31')\n",
    "actual_2021 = df_2021['Close'].values\n",
    "dates_2021 = df_2021.index\n",
    "\n",
    "# Prepare test data\n",
    "test_data = combined_data[-60:]  # Last 60 days of 2020\n",
    "X_test = np.array([test_data])  # Shape: (1, 60, 2)\n",
    "\n",
    "# Predict iteratively for each day in Jan 2021\n",
    "predicted_scaled = []\n",
    "for _ in range(len(actual_2021)):\n",
    "    pred = model.predict(X_test, verbose=0)\n",
    "    predicted_scaled.append(pred[0, 0])\n",
    "    \n",
    "    # Dynamic update of X_test with prediction and sentiment\n",
    "    next_entry = np.array([[pred[0, 0], average_sentiment]])\n",
    "    X_test = np.append(X_test[:, 1:, :], [next_entry], axis=1)\n",
    "\n",
    "# --- Inverse Transform ---\n",
    "predicted_scaled = np.array(predicted_scaled).reshape(-1, 1)\n",
    "predicted_prices = scaler_close.inverse_transform(predicted_scaled).flatten()\n",
    "\n",
    "# --- Final Comparison ---\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Date': dates_2021.to_numpy(),\n",
    "    'Actual Price': actual_2021.flatten(),\n",
    "    'Predicted Price': predicted_prices\n",
    "})\n",
    "\n",
    "print(comparison_df.round(2))\n",
    "\n",
    "\n",
    "\n",
    "# --- Export to CSV ---\n",
    "comparison_df.to_csv(\"tesla_2021_january_comparison.csv\", index=False)\n",
    "print(\"Saved to 'tesla_2021_january_comparison.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0f77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
